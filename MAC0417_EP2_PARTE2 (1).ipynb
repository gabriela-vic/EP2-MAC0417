{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "### EP2 MAC0417 / MAC5768 ##################################################################\n",
        "# AO PREENCHER ESSE CABEÇALHO COM O MEU NOME E O MEU NÚMERO USP,#\n",
        "# DECLARO QUE SOU O ÚNICO AUTOR E RESPONSÁVEL PELA RESOLUÇÃO #\n",
        "# DESTE EP. # # TODAS AS PARTES FORAM DESENVOLVIDAS E IMPLEMENTADAS POR MIM, #\n",
        "# SEGUINDO AS INSTRUÇÕES E QUE PORTANTO, NÃO CONSTITUEM # # DESONESTIDADE ACADÊMICA OU PLÁGIO. #\n",
        "## # DECLARO TAMBÉM, QUE SOU RESPONSÁVEL POR TODAS AS CÓPIAS # # DESSE PROGRAMA, E QUE EU NÃO DISTRIBUI OU FACILITEI A #\n",
        "# SUA DISTRIBUIÇÃO. ESTOU CIENTE QUE OS CASOS DE PLÁGIO E # # DESONESTIDADE ACADÊMICA SERÃO TRATADOS SEGUNDO OS CRITÉRIOS #\n",
        "# DEFINIDOS NO CÓDIGO DE ÉTICA DA USP. # ## # ENTENDO QUE JUPYTER NOTEBOOKS SEM ASSINATURA NÃO SERÃO #\n",
        "# CORRIGIDOS E, AINDA ASSIM, PODERÃO SER PUNIDOS POR # # DESONESTIDADE ACADÊMICA. #\n",
        "## ##\n",
        "# Nome: Gabriela Victor #\n",
        "# NUSP: 11795381 #\n",
        "# Turma: MAC0417 145    #\n",
        "# Prof.: Ronaldo Fumio Hashimoto #\n",
        "##################################################################"
      ],
      "metadata": {
        "id": "00I1mk-vcM7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "anUVJgw52hdH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imread\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git clone https://github.com/gabriela-vic/EP2-MAC0417\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdc7QaMuikdB",
        "outputId": "7add2dac-7848-4526-bf37-9a30dea48999"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EP2-MAC0417'...\n",
            "remote: Enumerating objects: 232, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 232 (delta 2), reused 119 (delta 1), pack-reused 112\u001b[K\n",
            "Receiving objects: 100% (232/232), 98.57 MiB | 17.25 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "Updating files: 100% (219/219), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('EP2-MAC0417')"
      ],
      "metadata": {
        "id": "t8iCysokppot"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omDtbgUErHRG",
        "outputId": "acf57faf-0f5e-4ec8-e4fa-ff9f6884b681"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['augmentationDataSet',\n",
              " 'MAC0417_EP2_PARTE1.ipynb',\n",
              " 'originalGrayDataSet',\n",
              " '.git']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Função de equalização de histograma\n",
        "def equalize_histogram(img):\n",
        "\n",
        "    hist, bins = np.histogram(img.flatten(), 256, [0,256])\n",
        "    cdf = hist.cumsum()\n",
        "    cdf_normalized = cdf * hist.max()/ cdf.max()\n",
        "\n",
        "\n",
        "    cdf_m = np.ma.masked_equal(cdf, 0)\n",
        "    cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
        "    cdf = np.ma.filled(cdf_m, 0).astype('uint8')\n",
        "\n",
        "\n",
        "    img_equalized = cdf[img]\n",
        "    return img_equalized\n",
        "\n",
        "# Função para calcular o histograma médio\n",
        "def calculate_average_histogram(image_files, dir_path):\n",
        "    histograms = []\n",
        "    for image_file in image_files:\n",
        "        img_path = os.path.join(dir_path, image_file)\n",
        "        img = plt.imread(img_path)\n",
        "        if img.ndim == 3:\n",
        "            img = np.dot(img[..., :3], [0.2989, 0.5870, 0.1140])  # Converter para escala de cinza\n",
        "\n",
        "        # Calcular histograma\n",
        "        hist, bins = np.histogram(img.flatten(), 256, [0,256])\n",
        "        histograms.append(hist)\n",
        "\n",
        "    # Calcular histograma médio\n",
        "    avg_hist = np.mean(histograms, axis=0)\n",
        "    return avg_hist\n",
        "\n",
        "# Caminhos dos diretórios e arquivos\n",
        "original_gray_dir = \"/content/EP2-MAC0417/grayscaleDataSet\"\n",
        "augmented_dir = \"/content/EP2-MAC0417/augmentationDataSet\"\n",
        "normalized_dir = \"/content/EP2-MAC0417/normalizedDataSet\"\n",
        "\n",
        "original_gray_csv_path = os.path.join(original_gray_dir, \"grayscaleDataSet.csv\")\n",
        "augmented_csv_path = os.path.join(augmented_dir, \"augmentationDataSet.csv\")\n",
        "\n",
        "# Carregar CSVs\n",
        "df_original = pd.read_csv(original_gray_csv_path)\n",
        "df_augmented = pd.read_csv(augmented_csv_path)\n",
        "\n",
        "# Criar diretório normalizedDataset se não existir\n",
        "if not os.path.exists(normalized_dir):\n",
        "    os.makedirs(normalized_dir)\n",
        "\n",
        "# Normalizar imagens do augmentedDataset\n",
        "for image_file in df_augmented['filename']:\n",
        "    img_path = os.path.join(augmented_dir, image_file)\n",
        "    img = plt.imread(img_path)\n",
        "    if img.ndim == 3:\n",
        "        img = np.dot(img[..., :3], [0.2989, 0.5870, 0.1140])  # Converter para escala de cinza\n",
        "\n",
        "    # Aplicar equalização de histograma\n",
        "    norm_img = equalize_histogram(img)\n",
        "\n",
        "    # Salvar imagem normalizada\n",
        "    norm_img_path = os.path.join(normalized_dir, image_file)\n",
        "    plt.imsave(norm_img_path, norm_img, cmap='gray')\n",
        "\n",
        "# Calcular histogramas médios\n",
        "hist_original = calculate_average_histogram(df_original['filename'], original_gray_dir)\n",
        "hist_augmented = calculate_average_histogram(df_augmented['filename'], augmented_dir)\n",
        "hist_normalized = calculate_average_histogram(df_augmented['filename'], normalized_dir)\n",
        "\n",
        "# Visualizar uma amostra de imagens antes e depois da normalização\n",
        "def plot_image_comparison(original_img, normalized_img, title_original='Original', title_normalized='Normalized'):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(original_img, cmap='gray')\n",
        "    plt.title(title_original)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(normalized_img, cmap='gray')\n",
        "    plt.title(title_normalized)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "sample_images = df_augmented['filename'].sample(3)\n",
        "for image_file in sample_images:\n",
        "    original_img_path = os.path.join(augmented_dir, image_file)\n",
        "    normalized_img_path = os.path.join(normalized_dir, image_file)\n",
        "\n",
        "    original_img = plt.imread(original_img_path)\n",
        "    if original_img.ndim == 3:\n",
        "        original_img = np.dot(original_img[..., :3], [0.2989, 0.5870, 0.1140])  # Converter para escala de cinza\n",
        "\n",
        "    normalized_img = plt.imread(normalized_img_path)\n",
        "    if normalized_img.ndim == 3:\n",
        "        normalized_img = np.dot(normalized_img[..., :3], [0.2989, 0.5870, 0.1140])  # Converter para escala de cinza\n",
        "\n",
        "    plot_image_comparison(original_img, normalized_img)\n",
        "\n",
        "# Plotar histogramas médios\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(hist_original, label='Original Gray')\n",
        "plt.plot(hist_augmented, label='Augmented')\n",
        "plt.plot(hist_normalized, label='Normalized')\n",
        "plt.title('Histogramas Médios')\n",
        "plt.xlabel('Intensidade')\n",
        "plt.ylabel('Frequência')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "loPxLkg4w1Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "051NamhXw0x-"
      }
    }
  ]
}